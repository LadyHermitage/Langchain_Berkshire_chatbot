{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LadyHermitage/Langchain_Berkshire_chatbot/blob/main/LangChain_chatbot_BerkshireHathaway.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "414b67d7-7183-4ae3-98ff-984ccc81d313",
      "metadata": {
        "id": "414b67d7-7183-4ae3-98ff-984ccc81d313"
      },
      "source": [
        "# Creating a chatbot on select data (10 years of Berkshire Hathaway letters)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c96ec017-8b29-4750-8344-eb1cda959b7e",
      "metadata": {
        "id": "c96ec017-8b29-4750-8344-eb1cda959b7e"
      },
      "source": [
        "MY STORY\n",
        "When I worked as a Knowledge Manager within an infrastructure team at Square/Block, I could see the role AI would play in my field. All of our internal documentation could be queried by a chatbot. No more hunting and pecking or tapping people by Slack. Information operations would become more efficient and comprehensive.  \n",
        "\n",
        "Alas, tech layoffs! I did not have the opportunity to implement this but I did still have my enthusiam and curiosity. Over the next 3 months, I learned about ML > generative AI > NLP > LLMs > Python > Pandas > SQL > IDEs > Langchain and more!\n",
        "\n",
        "Now, I understand what it takes to create this tool (thanks to Code Acedemy, Kaggle and DeepLearning.ai) and it looks a little something like this...hit it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f0c90e2-8c4d-4c77-aa29-f2b27aed3705",
      "metadata": {
        "id": "5f0c90e2-8c4d-4c77-aa29-f2b27aed3705"
      },
      "outputs": [],
      "source": [
        "# Set up with your OpenAI API key\n",
        "import os\n",
        "import openai\n",
        "import sys\n",
        "sys.path.append('../..')\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "openai.api_key  = os.environ['OPENAI_API_KEY']\n",
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2d872b0-f441-4078-980d-74ac4665df3d",
      "metadata": {
        "id": "c2d872b0-f441-4078-980d-74ac4665df3d"
      },
      "outputs": [],
      "source": [
        "#! pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ed44e84-c713-4347-b928-51a7409aeb0b",
      "metadata": {
        "id": "4ed44e84-c713-4347-b928-51a7409aeb0b"
      },
      "outputs": [],
      "source": [
        "#! pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3875b5cd-92c5-45e0-b44a-28dda152c0a0",
      "metadata": {
        "id": "3875b5cd-92c5-45e0-b44a-28dda152c0a0"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# Load your data\n",
        "loaders = [\n",
        "    # You need to update to the location on your machine\n",
        "    PyPDFLoader(\"/BerkshireHathaway_letters/2013ltr.pdf\"),\n",
        "    PyPDFLoader(\"/BerkshireHathaway_letters/2014ltr.pdf\"),\n",
        "    PyPDFLoader(\"/BerkshireHathaway_letters/2015ltr.pdf\"),\n",
        "    PyPDFLoader(\"/BerkshireHathaway_letters/2016ltr.pdf\"),\n",
        "    PyPDFLoader(\"/BerkshireHathaway_letters/2017ltr.pdf\"),\n",
        "    PyPDFLoader(\"/BerkshireHathaway_letters/2018ltr.pdf\"),\n",
        "    PyPDFLoader(\"/BerkshireHathaway_letters/2019ltr.pdf\"),\n",
        "    PyPDFLoader(\"/BerkshireHathaway_letters/2020ltr.pdf\"),\n",
        "    PyPDFLoader(\"/BerkshireHathaway_letters/2021ltr.pdf\"),\n",
        "    PyPDFLoader(\"/BerkshireHathaway_letters/2022ltr.pdf\")\n",
        "]\n",
        "docs = []\n",
        "for loader in loaders:\n",
        "    docs.extend(loader.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2eee727-ed1f-4169-94d3-de919930bab4",
      "metadata": {
        "id": "a2eee727-ed1f-4169-94d3-de919930bab4"
      },
      "outputs": [],
      "source": [
        "# Split the docs\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
        "splits = text_splitter.split_documents(docs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52cbd4ea-bc01-42e4-af7f-6fed57975ac6",
      "metadata": {
        "id": "52cbd4ea-bc01-42e4-af7f-6fed57975ac6"
      },
      "outputs": [],
      "source": [
        "# Set up embeddings\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "embedding = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e371c60-a3d2-4313-ba90-3063b97a63a4",
      "metadata": {
        "id": "8e371c60-a3d2-4313-ba90-3063b97a63a4"
      },
      "outputs": [],
      "source": [
        "#! pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ca617ea-efec-49f7-97a0-2597f5dfc7ad",
      "metadata": {
        "id": "5ca617ea-efec-49f7-97a0-2597f5dfc7ad"
      },
      "outputs": [],
      "source": [
        "# Set up the vector store\n",
        "from langchain.vectorstores import Chroma\n",
        "# You need to update to the location on your machine\n",
        "persist_directory = '/docs/chroma/'\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory\n",
        ")\n",
        "vectordb.persist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab46f2e5-4a03-4fab-9a13-0c4d91501c50",
      "metadata": {
        "id": "ab46f2e5-4a03-4fab-9a13-0c4d91501c50"
      },
      "outputs": [],
      "source": [
        "# Set up retriever\n",
        "from langchain.chains import RetrievalQA,  ConversationalRetrievalChain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0),\n",
        "    retriever=vectordb.as_retriever()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a7eba85-22a5-4356-b93a-f4a079154f3b",
      "metadata": {
        "id": "1a7eba85-22a5-4356-b93a-f4a079154f3b"
      },
      "outputs": [],
      "source": [
        "# Set up system prompt\n",
        "from langchain.prompts import PromptTemplate\n",
        "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer.\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0),\n",
        "    retriever=vectordb.as_retriever(),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f89d226-4243-46d6-bda9-311376b94140",
      "metadata": {
        "id": "5f89d226-4243-46d6-bda9-311376b94140"
      },
      "outputs": [],
      "source": [
        "# Set up chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0),\n",
        "    retriever=vectordb.as_retriever(),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dd69cd4-d23b-4393-911d-09f5575b8f1a",
      "metadata": {
        "id": "6dd69cd4-d23b-4393-911d-09f5575b8f1a"
      },
      "outputs": [],
      "source": [
        "# Finally, enter your question!\n",
        "question = \"What is The Secret Sauce?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92c15cc1-450c-4bcd-816c-60c6ff33412b",
      "metadata": {
        "id": "92c15cc1-450c-4bcd-816c-60c6ff33412b"
      },
      "outputs": [],
      "source": [
        "result = qa_chain({\"query\": question})\n",
        "result[\"result\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5209277d-d3ea-4161-b7e4-ac64c2ef0ccb",
      "metadata": {
        "id": "5209277d-d3ea-4161-b7e4-ac64c2ef0ccb"
      },
      "outputs": [],
      "source": [
        "# Check the source doc\n",
        "result[\"source_documents\"][0]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}